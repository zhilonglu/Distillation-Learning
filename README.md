# KnowledgeDistillation

All materials related to Knowledge Distillation

## Papers


## Codes
* [Alignahead: Online Cross-Layer Knowledge Extraction on Graph Neural Networks](https://github.com/GuoJY-eatsTG/Alignahead)


## Open-source Implementations
* [Awesome Knowledge Distillation](https://github.com/dkozlov/awesome-knowledge-distillation)
* [Awesome Knowledge-Distillation](https://github.com/FLHonker/Awesome-Knowledge-Distillation)
* [Pytorch implementation of various Knowledge Distillation (KD) methods](https://github.com/AberHu/Knowledge-Distillation-Zoo)
* [A PyTorch implementation for exploring deep and shallow knowledge distillation (KD) experiments with flexibility](https://github.com/peterliht/knowledge-distillation-pytorch)

